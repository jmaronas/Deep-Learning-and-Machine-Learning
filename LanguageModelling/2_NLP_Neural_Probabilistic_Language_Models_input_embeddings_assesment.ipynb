{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98469540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import pdfplumber\n",
    "import unicodedata\n",
    "from typing import List\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from IPython.display import Markdown, display, Video\n",
    "%load_ext jupyter_tikz\n",
    "\n",
    "assesment_draw_and_fill = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f906a1a-3ac1-4364-93ff-044f8042f1ae",
   "metadata": {},
   "source": [
    "**Disclaimer:** This notebook pretends to be didactic, introducing the ideas behind the concepts used to train neural probabilistic language models. This means that, modern models are implemented using advanced algorithms based on these ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f2cab-e7d8-4fa5-a114-9a090b0dddef",
   "metadata": {},
   "source": [
    "# Text representation through Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41e411-a329-490f-9794-43d46644853c",
   "metadata": {},
   "source": [
    "As you might imagine since machine learning is about math on computers we need to be able to represent text through some numerical representation. \n",
    "\n",
    "In the previous assesment we have seen the concept of tokenizer which, for a given text, find the fundamental elements and represent them with a number from $0$ to $\\mid V\\mid -1$. This is obviously a numerical representation but not a good one. Why? well it do not naturally handle things such as how many elements from a token appears in a text or what is the relation between words, because we know language have relation between its elements. Also, is a one dimensional representation and we are imposing an ordering which do not reflect reality. Why should we give token id 1 to word \"hola\" and token id 100 to word \"adios\"?. The relation between numbers do not somehow reflect their relation. Moreover a one dimensional input does not look like a good representation of a high dimensional problem. Moreover, how do you \n",
    "represent sentences, by summing up the token id from all of its elements?. Again, this does not make too much sense.\n",
    "\n",
    "So we will be representing data with vectors, where, each individual token will have its vector representation. However, we could perfectly have vector representations made up from sentences, paragraph or whatever thing we want. This is usually done by either using vector representations from individual words (for example by summing up their representations), or by using projected parts of different machine learning models (usually neural networks).\n",
    "\n",
    "Vector representations are usually of two types: lexical or also known as sparse, and semantic or also known as dense. It is important to note that lexical vectors (up to my knowledge) can only be obtained through representations of the individual tokens, while semantic vectors can be obtained either from semantic representations of words, or from projected parts of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf630536-91eb-47dc-adcb-347f5a71de83",
   "metadata": {},
   "source": [
    "## Lexical embeddings\n",
    "\n",
    "Lexical embeddings are vector representations of text that are based on the lexical content of a text, i.e. it does not capture semantic meaning. In other words, it is based on lexical features such as words, pronouns and so on (think that you could have a tokenizer that assigns tokens to different pronouns and roots of words and so preprocessing is in charge of splitting the pronoun from the word itself etc).\n",
    "\n",
    "Using the tokenizer we can have different word representations and the purpose of this assessment is not to explain them in detail. For that, we have the theory section.\n",
    "\n",
    "Note that, as you will see, lexical representation are also known as sparse representation because they end up being vector representations full of $0s$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f3cc78-ed76-45b5-9498-1488f5118e06",
   "metadata": {},
   "source": [
    "### One hot representation\n",
    "\n",
    "Using the token id, we can create a vector of size $\\mid V\\mid$ and place a $1$ in the place corresponding to token id. This is obviously a sparse representation and does not look like very useful. Just think why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc82c87-b156-4815-b741-a701ed0ac55d",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "Bag of words is the \"useful\" extension of the one-hot representation. The idea is to represent a sentence by a vector of size $\\mid V\\mid$ summing up all the one hot vectors from the individual words. This result in a vector where for each position in the vector of a token id we have a number representing the number of times this occurrence appears. Let's test this bag of word representation. For this, first use this code from the previous assessment. We are basically reading the document and use our class tokenizer to normalize and preprocess the text. Remember this step is common to any vector representation:\n",
    "\n",
    "```python\n",
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        # regular expression to get tokens by words and punctuation signs.\n",
    "        self.re_get_tokens = re.compile(r'\\w+|[^\\w\\s]+')\n",
    "        # regular expression to replace string splitters such as \\t \\n etc with whatever\n",
    "        self.re_replace_string_splitters = re.compile(r'\\s+')\n",
    "        # regular expression to split by underscore \"_\"\n",
    "        self.split_by_underscore = re.compile(r'_+|[^_]+')\n",
    "        # word to id dictionary\n",
    "        self.word_to_ids = None\n",
    "    \n",
    "    def encode(self, data:str):\n",
    "        \"\"\"Convert raw data to corresponding token list\"\"\"\n",
    "        assert self.word_to_ids is not None, \"Tokenizer has not been train. Call self.train_tokenizer\"\n",
    "\n",
    "        proc_data = self._normalize(data)\n",
    "        proc_data = self._pre_tokenize(proc_data)\n",
    "\n",
    "        tokens = []\n",
    "        for token_text in proc_data:\n",
    "            tokens.append(self.word_to_ids[token_text])\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def batch_encode(self, data:list):\n",
    "        \"\"\"Convert a list containing raw data to a list containing their corresponding token lists.\"\"\"\n",
    "        tokens = []\n",
    "        for d in data:\n",
    "            tokens.append(self.encode(d))\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens: List[int]):\n",
    "        \"\"\"Given a list of tokens, conver it to a string replacing tokens with text\"\"\"\n",
    "        assert self.word_to_ids is not None, \"Tokenizer has not been train. Call self.train_tokenizer\"\n",
    "        \n",
    "        text = [self.ids_to_word[t] for t in tokens]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def batch_decode(self, tokens : List[List[int]]):\n",
    "        \"\"\"Given a list containing list of tokens, convert it to a list containing strings replacing the tokens with text.\"\"\"\n",
    "        text = []\n",
    "        for t in tokens:\n",
    "            text.append(self.decode(t))\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def train_tokenizer(self, raw_data):\n",
    "        \"\"\"Given raw data create the token ids by applying the normalization step, pre tokenization step, training step and post tokenization\"\"\"\n",
    "        print(\"Normalizing data...\")\n",
    "        proc_data = self._normalize(raw_data)\n",
    "        \n",
    "        print(\"Pre tokenizing data...\")\n",
    "        proc_data = self._pre_tokenize(proc_data)\n",
    "        \n",
    "        print(\"Building vocabulary...\")\n",
    "        self.vocab = set(proc_data)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        # create mappings between words and ids and ids vs word for encoding and decoding\n",
    "        print(\"Building ids to word mappings...\")\n",
    "        self.word_to_ids = {}\n",
    "        self.ids_to_word = {}\n",
    "        for i, word in enumerate(self.vocab):\n",
    "            self.word_to_ids[word] = i\n",
    "            self.ids_to_word[i] = word\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the vocabulary\"\"\"\n",
    "        return self.vocab_size\n",
    "        \n",
    "    def _normalize(self, raw_data):\n",
    "        \"\"\"Applies normalization steps to raw data\"\"\"\n",
    "        ## make lower\n",
    "        proc_data = raw_data.lower()\n",
    "        \n",
    "        ## remove accents\n",
    "        proc_data = unicodedata.normalize(\"NFD\", proc_data)\n",
    "        proc_data = re.sub(r'[\\u0301\\u0300\\u0302]', '', proc_data)\n",
    "        proc_data = unicodedata.normalize(\"NFC\", proc_data)\n",
    "        \n",
    "        ## remove more than one separator into blank space\n",
    "        proc_data = self.re_replace_string_splitters.sub(' ', proc_data)\n",
    "\n",
    "        return proc_data\n",
    "\n",
    "    def _pre_tokenize(self, proc_data):\n",
    "        \"\"\"Apply pre tokenization step to normalized data\"\"\"\n",
    "\n",
    "        tokens = []\n",
    "        for t in self.split_by_underscore.findall(proc_data):\n",
    "            tokens.extend(self.re_get_tokens.findall(t))\n",
    "    \n",
    "        return tokens\n",
    "\n",
    "## read data from source to train language model on \n",
    "raw_data = \"\"\n",
    "\n",
    "## reading dataset with PDF Plumber\n",
    "with pdfplumber.open('data/texto_pdf.pdf') as pdf:\n",
    "    for page in pdf.pages:\n",
    "        raw_data += page.extract_text()\n",
    "\n",
    "## define tokenizer implementing\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "print(\"Normalizing data...\")\n",
    "proc_data = tokenizer._normalize(raw_data)\n",
    "\n",
    "print(\"Pre tokenizing data...\")\n",
    "proc_data = tokenizer._pre_tokenize(proc_data)\n",
    "\n",
    "## Reconstruct text from tokenized data\n",
    "data = ' '.join(proc_data)\n",
    "\n",
    "print(data)\n",
    "```\n",
    "\n",
    "Once we have this code, we will use sklearn (note I love to code up my algorithms but since bow and tfidif are boring to code up I'll use a library. In the future I might place my implementations here) to implement Bag of words representation. Note that skleaern BOW implementation will apply normalization and preprocessing internally but I'd like to already provide it with a clean data. Then, internally, it will create the vocabulary and create the vector representation I am mentioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4712e065-9d55-45ea-9814-65b3ad34ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data...\n",
      "Pre tokenizing data...\n",
      "redes neuronales redes neuronales y como funcionan inspiracion en el cerebro : las redes neuronales estan inspiradas en como funciona el cerebro humano . nuestro cerebro , especificamente el area visual , recibe informacion visual ( como lo que vemos ) y empieza por detectar cosas simples como lineas o bordes . luego , va construyendo cosas mas complejas , como formas , objetos , y finalmente , cosas que reconocemos ( por ejemplo , una cara o un coche ). en las redes neuronales artificiales pasa algo parecido : las primeras \" capas \" de la red se encargan de cosas basicas como detectar lineas , y las capas mas profundas hacen un trabajo mas complejo , como identificar que es lo que la imagen representa . capas de una red : imagina que cada capa de la red es como una persona en una cadena de montaje . cada persona se especializa en hacer una cosa : las primeras solo detectan si hay lineas , otras mas adelante se encargan de juntar esas lineas y formar esquinas o curvas , y las ultimas capas se encargan de decirte si lo que ves es un numero o una letra . es como resolver un rompecabezas , capa por capa . clasificacion de imagenes ( ejemplo del mnist ) el problema clasico : en clase , habeis trabajado con un problema tipico de redes neuronales : clasificar imagenes de numeros escritos a mano ( del 0 al 9 ). el objetivo es que la red \" aprenda \" a reconocer cada numero a partir de una imagen . como aprende la red : imagina que tienes una red neuronal que empieza a mirar imagenes de numeros . al principio , solo detecta partes muy basicas : una linea horizontal o vertical . con el tiempo , empieza a entender que dos lineas juntas en una forma concreta representan un numero ( como el 1 o el 4 ). con suficientes ejemplos , la red aprendera a identificar que numero esta viendo . diferencias entre machine learning y deep learningmachine learning ( aprendizaje automatico ): es un conjunto de tecnicas para enseñar a las maquinas ( ordenadores ) a hacer tareas especificas basadas en datos . imagina que le das a la maquina muchos ejemplos de algo ( como fotos de gatos y perros ) y la maquina aprende a diferenciarlos . deep learning ( aprendizaje profundo ): es una rama de machine learning . lo que lo hace \" profundo \" es que usa muchas capas de redes neuronales para aprender a hacer tareas mas complejas . estas redes son como capas de cebolla : cada capa extrae una cosa diferente , y cuantas mas capas haya , mas compleja sera la informacion que la red podra entender . estructura de las redes neuronales capas sencillas y complejas : al principio , las redes neuronales solo detectan cosas simples como lineas o puntos . a medida que avanzamos en la red , estas capas empiezan a detectar formas mas complejas , como curvas o colores , y al final , las capas profundas ya son capaces de reconocer cosas como rostros o digitos . ejemplo practico : en el caso de clasificar numeros , las primeras capas podrian detectar solo si hay lineas verticales o horizontales . las capas mas profundas se encargarian de detectar formas completas ( como si es un circulo o una linea cruzada ). asi , la red es capaz de decir si el numero es un 3 , un 4 o un 8 . computacion y avances problemas de antes : en el pasado , habia un problema con la cantidad de datos que las redes neuronales podian procesar . por ejemplo , al trabajar con señales de voz o imagenes , la cantidad de informacion era tan grande que no habia computadoras lo suficientemente rapidas para procesarla . por eso , antes se usaban \" trucos \" para simplificar los datos antes de meterlos a la red . avances actuales : hoy en dia , con ordenadores mas potentes , podemos trabajar con datos mucho mas complejos , como señales de voz en bruto o imagenes de alta resolucion . un ejemplo seria el procesamiento de señales de audio , donde antiguamente se reducianlos datos a pequeños numeros para ahorrar tiempo y capacidad de computo . aplicaciones reales de las redes neuronales protein folding ( plegamiento de proteinas ): este fue un ejemplo que se dio en clase sobre como se usan las redes neuronales para resolver problemas en la biologia . antes , los cientificos tardaban mucho tiempo en predecir la estructura de una proteina , pero con redes neuronales , ahora pueden hacerlo mucho mas rapido . esto es clave para desarrollar medicamentos o estudiar enfermedades . conduccion autonoma ( tesla ): otro ejemplo es como se utilizan las redes neuronales en los coches que se conducen solos . el coche tiene redes neuronales que detectan cosas a su alrededor ( como peatones , coches o semaforos ) y otras que deciden que hacer en cada situacion ( como frenar o acelerar ). todo esto se hace combinando varias redes para que trabajen juntas . como aprende una red neuronal optimizacion y entrenamiento : una red neuronal aprende ajustando sus \" pesos \", que son como pequeños ajustes en como se procesan los datos . la red trata de encontrar los mejores ajustes para que , cuando vea un nuevo dato ( como una nueva imagen de un numero ), sea capaz de dar la respuesta correcta . por ejemplo : si le das a la red una foto de un numero , al principio , puede cometer errores . pero , con el tiempo , ajusta esos errores y se vuelve cada vez mas precisa , hasta que puede decirte con seguridad que numero esta viendo . otros algoritmos relacionados ademas de las redes neuronales , hay otros algoritmos en machine learning , como los algoritmos geneticos o los modelos de ciencia de datos , que tambien son utiles para resolver problemas especificos . por ejemplo : los algoritmos geneticos imitan el proceso de evolucion para encontrar soluciones a problemas complejos .\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        # regular expression to get tokens by words and punctuation signs.\n",
    "        self.re_get_tokens = re.compile(r'\\w+|[^\\w\\s]+')\n",
    "        # regular expression to replace string splitters such as \\t \\n etc with whatever\n",
    "        self.re_replace_string_splitters = re.compile(r'\\s+')\n",
    "        # regular expression to split by underscore \"_\"\n",
    "        self.split_by_underscore = re.compile(r'_+|[^_]+')\n",
    "        # word to id dictionary\n",
    "        self.word_to_ids = None\n",
    "    \n",
    "    def encode(self, data:str):\n",
    "        \"\"\"Convert raw data to corresponding token list\"\"\"\n",
    "        assert self.word_to_ids is not None, \"Tokenizer has not been train. Call self.train_tokenizer\"\n",
    "\n",
    "        proc_data = self._normalize(data)\n",
    "        proc_data = self._pre_tokenize(proc_data)\n",
    "\n",
    "        tokens = []\n",
    "        for token_text in proc_data:\n",
    "            tokens.append(self.word_to_ids[token_text])\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def batch_encode(self, data:list):\n",
    "        \"\"\"Convert a list containing raw data to a list containing their corresponding token lists.\"\"\"\n",
    "        tokens = []\n",
    "        for d in data:\n",
    "            tokens.append(self.encode(d))\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens: List[int]):\n",
    "        \"\"\"Given a list of tokens, conver it to a string replacing tokens with text\"\"\"\n",
    "        assert self.word_to_ids is not None, \"Tokenizer has not been train. Call self.train_tokenizer\"\n",
    "        \n",
    "        text = [self.ids_to_word[t] for t in tokens]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def batch_decode(self, tokens : List[List[int]]):\n",
    "        \"\"\"Given a list containing list of tokens, convert it to a list containing strings replacing the tokens with text.\"\"\"\n",
    "        text = []\n",
    "        for t in tokens:\n",
    "            text.append(self.decode(t))\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def train_tokenizer(self, raw_data):\n",
    "        \"\"\"Given raw data create the token ids by applying the normalization step, pre tokenization step, training step and post tokenization\"\"\"\n",
    "        print(\"Normalizing data...\")\n",
    "        proc_data = self._normalize(raw_data)\n",
    "        \n",
    "        print(\"Pre tokenizing data...\")\n",
    "        proc_data = self._pre_tokenize(proc_data)\n",
    "        \n",
    "        print(\"Building vocabulary...\")\n",
    "        self.vocab = set(proc_data)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        # create mappings between words and ids and ids vs word for encoding and decoding\n",
    "        print(\"Building ids to word mappings...\")\n",
    "        self.word_to_ids = {}\n",
    "        self.ids_to_word = {}\n",
    "        for i, word in enumerate(self.vocab):\n",
    "            self.word_to_ids[word] = i\n",
    "            self.ids_to_word[i] = word\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the vocabulary\"\"\"\n",
    "        return self.vocab_size\n",
    "        \n",
    "    def _normalize(self, raw_data):\n",
    "        \"\"\"Applies normalization steps to raw data\"\"\"\n",
    "        ## make lower\n",
    "        proc_data = raw_data.lower()\n",
    "        \n",
    "        ## remove accents\n",
    "        proc_data = unicodedata.normalize(\"NFD\", proc_data)\n",
    "        proc_data = re.sub(r'[\\u0301\\u0300\\u0302]', '', proc_data)\n",
    "        proc_data = unicodedata.normalize(\"NFC\", proc_data)\n",
    "        \n",
    "        ## remove more than one separator into blank space\n",
    "        proc_data = self.re_replace_string_splitters.sub(' ', proc_data)\n",
    "\n",
    "        return proc_data\n",
    "\n",
    "    def _pre_tokenize(self, proc_data):\n",
    "        \"\"\"Apply pre tokenization step to normalized data\"\"\"\n",
    "\n",
    "        tokens = []\n",
    "        for t in self.split_by_underscore.findall(proc_data):\n",
    "            tokens.extend(self.re_get_tokens.findall(t))\n",
    "    \n",
    "        return tokens\n",
    "\n",
    "## read data from source to train language model on \n",
    "raw_data = \"\"\n",
    "\n",
    "## reading dataset with PDF Plumber\n",
    "with pdfplumber.open('data/texto_pdf.pdf') as pdf:\n",
    "    for page in pdf.pages:\n",
    "        raw_data += page.extract_text()\n",
    "\n",
    "## define tokenizer implementing\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "print(\"Normalizing data...\")\n",
    "proc_data = tokenizer._normalize(raw_data)\n",
    "\n",
    "print(\"Pre tokenizing data...\")\n",
    "proc_data = tokenizer._pre_tokenize(proc_data)\n",
    "\n",
    "## Reconstruct text from tokenized data\n",
    "data = ' '.join(proc_data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c55990-a844-4c6e-a3cc-fe4c63ff8598",
   "metadata": {},
   "source": [
    "##### Task: Train a BOW vectorizer from sklearn.\n",
    "\n",
    "Get the processed data from previous code, fit the vectorizer and transform the following sentence:\n",
    "\n",
    "```python\n",
    "x = \"El Machine learning y redes neuronales son importantes. El machine learning más.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd0b945-7694-4b9b-8c48-858e160126e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "# BOW vectorizer\n",
       "vectorizer = ...\n",
       "\n",
       "# Normalize and tokenize\n",
       "vectorizer.fit_transform(...)\n",
       "\n",
       "# Get vocabulary\n",
       "palabras = vectorizer.get_feature_names_out()\n",
       "\n",
       "# Show the vocabulary\n",
       "print(palabras)\n",
       "\n",
       "# Now obtain the vector representation\n",
       "x = \"El Machine learning y redes neuronales son importantes. El machine learning más.\"\n",
       "embedding = ...\n",
       "\n",
       "print(embedding.toarray())\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if assesment_draw_and_fill:\n",
    "    code = \"\"\"\n",
    "```python\n",
    "# BOW vectorizer\n",
    "vectorizer = ...\n",
    "\n",
    "# Normalize and tokenize\n",
    "vectorizer.fit_transform(...)\n",
    "\n",
    "# Get vocabulary\n",
    "palabras = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Show the vocabulary\n",
    "print(palabras)\n",
    "\n",
    "# Now obtain the vector representation\n",
    "x = \"El Machine learning y redes neuronales son importantes. El machine learning más.\"\n",
    "embedding = ...\n",
    "\n",
    "print(embedding.toarray())\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e8ab20-a067-4787-ba65-3a4a54fe9d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acelerar' 'actuales' 'adelante' 'ademas' 'ahora' 'ahorrar' 'ajusta'\n",
      " 'ajustando' 'ajustes' 'al' 'algo' 'algoritmos' 'alrededor' 'alta' 'antes'\n",
      " 'antiguamente' 'aplicaciones' 'aprenda' 'aprende' 'aprender' 'aprendera'\n",
      " 'aprendizaje' 'area' 'artificiales' 'asi' 'audio' 'automatico' 'autonoma'\n",
      " 'avances' 'avanzamos' 'basadas' 'basicas' 'biologia' 'bordes' 'bruto'\n",
      " 'cada' 'cadena' 'cantidad' 'capa' 'capaces' 'capacidad' 'capas' 'capaz'\n",
      " 'cara' 'caso' 'cebolla' 'cerebro' 'ciencia' 'cientificos' 'circulo'\n",
      " 'clase' 'clasico' 'clasificacion' 'clasificar' 'clave' 'coche' 'coches'\n",
      " 'colores' 'combinando' 'cometer' 'como' 'compleja' 'complejas' 'complejo'\n",
      " 'complejos' 'completas' 'computacion' 'computadoras' 'computo' 'con'\n",
      " 'concreta' 'conduccion' 'conducen' 'conjunto' 'construyendo' 'correcta'\n",
      " 'cosa' 'cosas' 'cruzada' 'cuando' 'cuantas' 'curvas' 'dar' 'das' 'dato'\n",
      " 'datos' 'de' 'deciden' 'decir' 'decirte' 'deep' 'del' 'desarrollar'\n",
      " 'detecta' 'detectan' 'detectar' 'dia' 'diferenciarlos' 'diferencias'\n",
      " 'diferente' 'digitos' 'dio' 'donde' 'dos' 'ejemplo' 'ejemplos' 'el'\n",
      " 'empieza' 'empiezan' 'en' 'encargan' 'encargarian' 'encontrar'\n",
      " 'enfermedades' 'enseñar' 'entender' 'entre' 'entrenamiento' 'era'\n",
      " 'errores' 'es' 'esas' 'escritos' 'eso' 'esos' 'especializa'\n",
      " 'especificamente' 'especificas' 'especificos' 'esquinas' 'esta' 'estan'\n",
      " 'estas' 'este' 'esto' 'estructura' 'estudiar' 'evolucion' 'extrae'\n",
      " 'final' 'finalmente' 'folding' 'forma' 'formar' 'formas' 'foto' 'fotos'\n",
      " 'frenar' 'fue' 'funciona' 'funcionan' 'gatos' 'geneticos' 'grande'\n",
      " 'habeis' 'habia' 'hace' 'hacen' 'hacer' 'hacerlo' 'hasta' 'hay' 'haya'\n",
      " 'horizontal' 'horizontales' 'hoy' 'humano' 'identificar' 'imagen'\n",
      " 'imagenes' 'imagina' 'imitan' 'informacion' 'inspiracion' 'inspiradas'\n",
      " 'juntar' 'juntas' 'la' 'las' 'le' 'learning' 'learningmachine' 'letra'\n",
      " 'linea' 'lineas' 'lo' 'los' 'luego' 'machine' 'mano' 'maquina' 'maquinas'\n",
      " 'mas' 'medicamentos' 'medida' 'mejores' 'meterlos' 'mirar' 'mnist'\n",
      " 'modelos' 'montaje' 'muchas' 'mucho' 'muchos' 'muy' 'neuronal'\n",
      " 'neuronales' 'no' 'nuestro' 'nueva' 'nuevo' 'numero' 'numeros' 'objetivo'\n",
      " 'objetos' 'optimizacion' 'ordenadores' 'otras' 'otro' 'otros' 'para'\n",
      " 'parecido' 'partes' 'partir' 'pasa' 'pasado' 'peatones' 'pequeños' 'pero'\n",
      " 'perros' 'persona' 'pesos' 'plegamiento' 'podemos' 'podian' 'podra'\n",
      " 'podrian' 'por' 'potentes' 'practico' 'precisa' 'predecir' 'primeras'\n",
      " 'principio' 'problema' 'problemas' 'procesamiento' 'procesan' 'procesar'\n",
      " 'procesarla' 'proceso' 'profundas' 'profundo' 'protein' 'proteina'\n",
      " 'proteinas' 'puede' 'pueden' 'puntos' 'que' 'rama' 'rapidas' 'rapido'\n",
      " 'reales' 'recibe' 'reconocemos' 'reconocer' 'red' 'redes' 'reducianlos'\n",
      " 'relacionados' 'representa' 'representan' 'resolucion' 'resolver'\n",
      " 'respuesta' 'rompecabezas' 'rostros' 'se' 'sea' 'seguridad' 'semaforos'\n",
      " 'sencillas' 'sera' 'seria' 'señales' 'si' 'simples' 'simplificar'\n",
      " 'situacion' 'sobre' 'solo' 'solos' 'soluciones' 'son' 'su'\n",
      " 'suficientemente' 'suficientes' 'sus' 'tambien' 'tan' 'tardaban' 'tareas'\n",
      " 'tecnicas' 'tesla' 'tiempo' 'tiene' 'tienes' 'tipico' 'todo' 'trabajado'\n",
      " 'trabajar' 'trabajen' 'trabajo' 'trata' 'trucos' 'ultimas' 'un' 'una'\n",
      " 'usa' 'usaban' 'usan' 'utiles' 'utilizan' 'va' 'varias' 'vea' 'vemos'\n",
      " 'vertical' 'verticales' 'ves' 'vez' 'viendo' 'visual' 'voz' 'vuelve' 'ya']\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# BOW vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Normalize and tokenize\n",
    "vectorizer.fit_transform([data])\n",
    "\n",
    "# Get vocabulary\n",
    "palabras = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Show the vocabulary\n",
    "print(palabras)\n",
    "\n",
    "# Now obtain the vector representation\n",
    "x = \"El Machine learning y redes neuronales son importantes. El machine learning más.\"\n",
    "embedding = vectorizer.transform([x])\n",
    "\n",
    "print(embedding.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3c245-e357-4e24-bdca-c39422c51fc4",
   "metadata": {},
   "source": [
    "## Semantic embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d08e6-a27e-458c-8a31-ccf184c7649b",
   "metadata": {},
   "source": [
    "Semantic input embeddings are usually learnt with the probabilistic optimization that implements a particular task (text generation, text summarization etc) and so they will be different. However we also have three popular (and very related algorithm) that are focus just on learning these representations of words, without being tailored to a particular task. In other words, some algorithms learnt vector representations while they are learning to perform some task, so the ultimate goal is these task, while there are three algorithms that are directly tailored to learn these representation, without being tailored to learning a particular task. \n",
    "\n",
    "These three algorithms are known as: \n",
    "\n",
    "* Non Linear Continous Bag of Words.\n",
    "* Continuous Bag of Words\n",
    "* Skip gram model.\n",
    "\n",
    "This assesment implements the Continuous Bag of Words model, which is the linear version of the Non-Linear Continous Bag of Words. Note that we could really join the CBOW and Non-Linear CBOW in something like CBOW models, where the practitioner might decide different versions of how the projected function is implemented. The CBOW, in its origin, is a linear model with a single linear projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b8848-3929-48e0-ab9f-2f0bea67a9ed",
   "metadata": {},
   "source": [
    "# CBOW Neural Probabilistic Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd046b-883f-4485-9e34-a9b49dc81715",
   "metadata": {},
   "source": [
    "The CBOW Neural probabilistic Language model is a language model which is trained to learn to predict the probability of a word, given its right and left context $C$. \n",
    "\n",
    "This probability is implemented as:\n",
    "\n",
    "$$\n",
    "p(w_t\\mid w_{t-C/2},\\dots,w_{t+C/2}) = \\text{softmax}\\left( \\sum_{-C/2 \\leq i \\leq C/2; i \\neq t} e_i^T \\cdot A \\right)\n",
    "$$\n",
    "\n",
    "where $A^{d\\times \\mid V\\mid}$ is a matrix and $e_t \\in \\mathbb{R}^{d}$ is the embedding corresponding to the word $t$. Both $A$ and each of the embeddings $e_t$ are learned to maximize this log probability for every word in the document (there are different tricks and particularities to do this efficiently such as hierarchical softmax, noise contrastive estimation, word subsampling \\etc).\n",
    "\n",
    "Note that this probability represents a classification problem to classify towards the label representing the word in the vocabulary (which in practice is the token id from your tokenizer).\n",
    "\n",
    "Note that, although we frame it as word prediction, we could implement this model over any type of token, even if it is a subword.\n",
    "\n",
    "The model is represented in the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffb6fa9-93d0-4f60-8e45-8f885912a133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"335.386pt\" height=\"312.509pt\" viewBox=\"0 0 335.386 312.509\" version=\"1.2\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.59375 -3.375 C 4.640625 -3.59375 4.734375 -3.953125 4.734375 -4.015625 C 4.734375 -4.1875 4.59375 -4.28125 4.453125 -4.28125 C 4.328125 -4.28125 4.15625 -4.203125 4.078125 -4 C 4.046875 -3.9375 3.59375 -2.03125 3.515625 -1.78125 C 3.453125 -1.484375 3.421875 -1.296875 3.421875 -1.125 C 3.421875 -1.015625 3.421875 -1 3.4375 -0.9375 C 3.203125 -0.421875 2.90625 -0.109375 2.53125 -0.109375 C 1.734375 -0.109375 1.734375 -0.84375 1.734375 -1.015625 C 1.734375 -1.328125 1.78125 -1.71875 2.25 -2.9375 C 2.359375 -3.234375 2.421875 -3.375 2.421875 -3.578125 C 2.421875 -4.03125 2.09375 -4.390625 1.59375 -4.390625 C 0.65625 -4.390625 0.28125 -2.953125 0.28125 -2.859375 C 0.28125 -2.765625 0.390625 -2.765625 0.40625 -2.765625 C 0.5 -2.765625 0.515625 -2.78125 0.5625 -2.9375 C 0.828125 -3.859375 1.21875 -4.171875 1.5625 -4.171875 C 1.65625 -4.171875 1.8125 -4.15625 1.8125 -3.84375 C 1.8125 -3.59375 1.703125 -3.3125 1.640625 -3.15625 C 1.203125 -1.984375 1.078125 -1.515625 1.078125 -1.140625 C 1.078125 -0.234375 1.75 0.109375 2.5 0.109375 C 2.65625 0.109375 3.125 0.109375 3.53125 -0.59375 C 3.78125 0.046875 4.46875 0.109375 4.765625 0.109375 C 5.515625 0.109375 5.953125 -0.515625 6.21875 -1.109375 C 6.546875 -1.890625 6.859375 -3.21875 6.859375 -3.703125 C 6.859375 -4.25 6.59375 -4.390625 6.421875 -4.390625 C 6.1875 -4.390625 5.9375 -4.140625 5.9375 -3.921875 C 5.9375 -3.78125 6 -3.734375 6.078125 -3.640625 C 6.1875 -3.53125 6.4375 -3.28125 6.4375 -2.796875 C 6.4375 -2.46875 6.15625 -1.484375 5.890625 -0.984375 C 5.640625 -0.453125 5.28125 -0.109375 4.796875 -0.109375 C 4.328125 -0.109375 4.0625 -0.40625 4.0625 -0.96875 C 4.0625 -1.25 4.140625 -1.5625 4.171875 -1.703125 Z M 4.59375 -3.375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.453125 1.21875 C 0.375 1.546875 0.34375 1.625 -0.09375 1.625 C -0.203125 1.625 -0.3125 1.625 -0.3125 1.8125 C -0.3125 1.890625 -0.265625 1.921875 -0.1875 1.921875 C 0.078125 1.921875 0.375 1.890625 0.640625 1.890625 C 0.96875 1.890625 1.3125 1.921875 1.625 1.921875 C 1.671875 1.921875 1.8125 1.921875 1.8125 1.734375 C 1.8125 1.625 1.703125 1.625 1.5625 1.625 C 1.078125 1.625 1.078125 1.546875 1.078125 1.453125 C 1.078125 1.34375 1.484375 -0.28125 1.5625 -0.53125 C 1.6875 -0.234375 1.96875 0.109375 2.46875 0.109375 C 3.625 0.109375 4.875 -1.34375 4.875 -2.796875 C 4.875 -3.734375 4.296875 -4.390625 3.546875 -4.390625 C 3.046875 -4.390625 2.578125 -4.03125 2.25 -3.640625 C 2.140625 -4.1875 1.71875 -4.390625 1.34375 -4.390625 C 0.890625 -4.390625 0.703125 -4 0.609375 -3.828125 C 0.4375 -3.484375 0.3125 -2.890625 0.3125 -2.859375 C 0.3125 -2.765625 0.40625 -2.765625 0.421875 -2.765625 C 0.53125 -2.765625 0.53125 -2.765625 0.59375 -2.984375 C 0.765625 -3.703125 0.96875 -4.171875 1.328125 -4.171875 C 1.484375 -4.171875 1.625 -4.09375 1.625 -3.71875 C 1.625 -3.484375 1.59375 -3.375 1.5625 -3.203125 Z M 2.203125 -3.09375 C 2.265625 -3.375 2.53125 -3.640625 2.71875 -3.796875 C 3.0625 -4.109375 3.34375 -4.171875 3.515625 -4.171875 C 3.921875 -4.171875 4.15625 -3.828125 4.15625 -3.234375 C 4.15625 -2.65625 3.828125 -1.515625 3.640625 -1.140625 C 3.3125 -0.4375 2.828125 -0.109375 2.46875 -0.109375 C 1.8125 -0.109375 1.671875 -0.9375 1.671875 -1 C 1.671875 -1.015625 1.671875 -1.03125 1.703125 -1.15625 Z M 2.203125 -3.09375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.015625 -0.015625 C 2.015625 -0.671875 1.765625 -1.046875 1.375 -1.046875 C 1.046875 -1.046875 0.859375 -0.8125 0.859375 -0.53125 C 0.859375 -0.265625 1.046875 0 1.375 0 C 1.5 0 1.625 -0.046875 1.734375 -0.125 C 1.765625 -0.15625 1.765625 -0.15625 1.78125 -0.15625 C 1.78125 -0.15625 1.796875 -0.15625 1.796875 -0.015625 C 1.796875 0.71875 1.453125 1.328125 1.125 1.65625 C 1.015625 1.765625 1.015625 1.78125 1.015625 1.8125 C 1.015625 1.875 1.0625 1.921875 1.109375 1.921875 C 1.21875 1.921875 2.015625 1.15625 2.015625 -0.015625 Z M 2.015625 -0.015625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.90625 -0.53125 C 1.90625 -0.8125 1.671875 -1.046875 1.375 -1.046875 C 1.09375 -1.046875 0.859375 -0.8125 0.859375 -0.53125 C 0.859375 -0.234375 1.09375 0 1.375 0 C 1.671875 0 1.90625 -0.234375 1.90625 -0.53125 Z M 1.90625 -0.53125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-5\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.78125 -1.140625 C 1.375 -0.484375 1 -0.34375 0.5625 -0.3125 C 0.4375 -0.296875 0.34375 -0.296875 0.34375 -0.109375 C 0.34375 -0.046875 0.390625 0 0.484375 0 C 0.75 0 1.046875 -0.03125 1.328125 -0.03125 C 1.65625 -0.03125 2 0 2.328125 0 C 2.390625 0 2.515625 0 2.515625 -0.1875 C 2.515625 -0.296875 2.421875 -0.3125 2.359375 -0.3125 C 2.125 -0.328125 1.890625 -0.40625 1.890625 -0.65625 C 1.890625 -0.78125 1.953125 -0.890625 2.03125 -1.03125 L 2.78125 -2.296875 L 5.28125 -2.296875 C 5.296875 -2.09375 5.4375 -0.734375 5.4375 -0.640625 C 5.4375 -0.34375 4.921875 -0.3125 4.71875 -0.3125 C 4.578125 -0.3125 4.484375 -0.3125 4.484375 -0.109375 C 4.484375 0 4.59375 0 4.625 0 C 5.03125 0 5.453125 -0.03125 5.859375 -0.03125 C 6.109375 -0.03125 6.734375 0 6.984375 0 C 7.046875 0 7.171875 0 7.171875 -0.203125 C 7.171875 -0.3125 7.0625 -0.3125 6.9375 -0.3125 C 6.3125 -0.3125 6.3125 -0.375 6.296875 -0.671875 L 5.6875 -6.875 C 5.671875 -7.078125 5.671875 -7.109375 5.5 -7.109375 C 5.34375 -7.109375 5.296875 -7.046875 5.234375 -6.953125 Z M 2.96875 -2.609375 L 4.921875 -5.890625 L 5.25 -2.609375 Z M 2.96875 -2.609375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.71875 -2.75 L 2.421875 -2.75 C 2.5625 -2.75 2.640625 -2.75 2.640625 -2.90625 C 2.640625 -3 2.5625 -3 2.4375 -3 L 1.78125 -3 L 2.03125 -4.03125 C 2.046875 -4.0625 2.0625 -4.109375 2.0625 -4.125 C 2.0625 -4.265625 1.953125 -4.359375 1.8125 -4.359375 C 1.640625 -4.359375 1.546875 -4.234375 1.484375 -4.0625 C 1.4375 -3.875 1.53125 -4.21875 1.21875 -3 L 0.515625 -3 C 0.390625 -3 0.296875 -3 0.296875 -2.84375 C 0.296875 -2.75 0.375 -2.75 0.5 -2.75 L 1.15625 -2.75 L 0.75 -1.109375 C 0.703125 -0.9375 0.640625 -0.6875 0.640625 -0.59375 C 0.640625 -0.1875 1 0.0625 1.390625 0.0625 C 2.171875 0.0625 2.609375 -0.90625 2.609375 -1 C 2.609375 -1.09375 2.515625 -1.09375 2.5 -1.09375 C 2.40625 -1.09375 2.40625 -1.078125 2.34375 -0.953125 C 2.15625 -0.515625 1.796875 -0.125 1.421875 -0.125 C 1.265625 -0.125 1.171875 -0.21875 1.171875 -0.46875 C 1.171875 -0.53125 1.203125 -0.6875 1.21875 -0.75 Z M 1.71875 -2.75 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 5.875 -4.8125 C 5.875 -4.84375 5.859375 -4.90625 5.78125 -4.90625 C 5.734375 -4.90625 5.71875 -4.890625 5.65625 -4.8125 L 5.15625 -4.28125 C 5.09375 -4.359375 4.703125 -4.90625 3.84375 -4.90625 C 2.140625 -4.90625 0.484375 -3.40625 0.484375 -1.828125 C 0.484375 -0.6875 1.375 0.140625 2.625 0.140625 C 3 0.140625 3.671875 0.0625 4.390625 -0.546875 C 4.9375 -1.015625 5.09375 -1.609375 5.09375 -1.671875 C 5.09375 -1.765625 5.015625 -1.765625 4.96875 -1.765625 C 4.890625 -1.765625 4.875 -1.734375 4.84375 -1.65625 C 4.5625 -0.703125 3.59375 -0.109375 2.75 -0.109375 C 2 -0.109375 1.1875 -0.515625 1.1875 -1.609375 C 1.1875 -1.8125 1.234375 -2.90625 2.03125 -3.796875 C 2.515625 -4.328125 3.25 -4.640625 3.90625 -4.640625 C 4.71875 -4.640625 5.1875 -4.0625 5.1875 -3.28125 C 5.1875 -3.09375 5.171875 -3.03125 5.171875 -3 C 5.171875 -2.90625 5.265625 -2.90625 5.296875 -2.90625 C 5.40625 -2.90625 5.40625 -2.921875 5.4375 -3.0625 Z M 5.875 -4.8125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.484375 -4.921875 C 3.53125 -5.015625 3.53125 -5.03125 3.53125 -5.046875 C 3.53125 -5.15625 3.4375 -5.21875 3.359375 -5.21875 C 3.25 -5.21875 3.21875 -5.140625 3.171875 -5.046875 L 0.578125 1.4375 C 0.53125 1.53125 0.53125 1.546875 0.53125 1.5625 C 0.53125 1.671875 0.625 1.734375 0.703125 1.734375 C 0.828125 1.734375 0.859375 1.65625 0.890625 1.5625 Z M 3.484375 -4.921875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 5.1875 -1.578125 C 5.296875 -1.578125 5.46875 -1.578125 5.46875 -1.734375 C 5.46875 -1.921875 5.296875 -1.921875 5.1875 -1.921875 L 1.03125 -1.921875 C 0.921875 -1.921875 0.75 -1.921875 0.75 -1.75 C 0.75 -1.578125 0.90625 -1.578125 1.03125 -1.578125 Z M 5.1875 -1.578125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph3-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph3-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.515625 -1.265625 L 3.28125 -1.265625 C 3.265625 -1.109375 3.1875 -0.703125 3.09375 -0.640625 C 3.046875 -0.59375 2.515625 -0.59375 2.40625 -0.59375 L 1.125 -0.59375 C 1.859375 -1.234375 2.109375 -1.4375 2.515625 -1.765625 C 3.03125 -2.171875 3.515625 -2.609375 3.515625 -3.265625 C 3.515625 -4.109375 2.78125 -4.625 1.890625 -4.625 C 1.03125 -4.625 0.4375 -4.015625 0.4375 -3.375 C 0.4375 -3.03125 0.734375 -2.984375 0.8125 -2.984375 C 0.96875 -2.984375 1.171875 -3.109375 1.171875 -3.359375 C 1.171875 -3.484375 1.125 -3.734375 0.765625 -3.734375 C 0.984375 -4.21875 1.453125 -4.375 1.78125 -4.375 C 2.484375 -4.375 2.84375 -3.828125 2.84375 -3.265625 C 2.84375 -2.65625 2.40625 -2.1875 2.1875 -1.9375 L 0.515625 -0.265625 C 0.4375 -0.203125 0.4375 -0.1875 0.4375 0 L 3.3125 0 Z M 3.515625 -1.265625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph3-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.328125 -4.4375 C 2.328125 -4.625 2.328125 -4.625 2.125 -4.625 C 1.671875 -4.1875 1.046875 -4.1875 0.765625 -4.1875 L 0.765625 -3.9375 C 0.921875 -3.9375 1.390625 -3.9375 1.765625 -4.125 L 1.765625 -0.578125 C 1.765625 -0.34375 1.765625 -0.25 1.078125 -0.25 L 0.8125 -0.25 L 0.8125 0 C 0.9375 0 1.796875 -0.03125 2.046875 -0.03125 C 2.265625 -0.03125 3.140625 0 3.296875 0 L 3.296875 -0.25 L 3.03125 -0.25 C 2.328125 -0.25 2.328125 -0.34375 2.328125 -0.578125 Z M 2.328125 -4.4375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph3-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.21875 -1.578125 L 5.359375 -1.578125 C 5.453125 -1.578125 5.609375 -1.578125 5.609375 -1.734375 C 5.609375 -1.921875 5.453125 -1.921875 5.359375 -1.921875 L 3.21875 -1.921875 L 3.21875 -4.0625 C 3.21875 -4.140625 3.21875 -4.3125 3.0625 -4.3125 C 2.890625 -4.3125 2.890625 -4.15625 2.890625 -4.0625 L 2.890625 -1.921875 L 0.75 -1.921875 C 0.65625 -1.921875 0.484375 -1.921875 0.484375 -1.75 C 0.484375 -1.578125 0.640625 -1.578125 0.75 -1.578125 L 2.890625 -1.578125 L 2.890625 0.5625 C 2.890625 0.65625 2.890625 0.828125 3.046875 0.828125 C 3.21875 0.828125 3.21875 0.65625 3.21875 0.5625 Z M 3.21875 -1.578125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph4-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph4-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.90625 -0.53125 C 1.90625 -0.8125 1.671875 -1.046875 1.375 -1.046875 C 1.09375 -1.046875 0.859375 -0.8125 0.859375 -0.53125 C 0.859375 -0.234375 1.09375 0 1.375 0 C 1.671875 0 1.90625 -0.234375 1.90625 -0.53125 Z M 1.90625 -0.53125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph4-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.296875 2.390625 C 3.296875 2.359375 3.296875 2.328125 3.125 2.171875 C 1.875 0.921875 1.5625 -0.96875 1.5625 -2.484375 C 1.5625 -4.21875 1.9375 -5.9375 3.15625 -7.1875 C 3.296875 -7.296875 3.296875 -7.328125 3.296875 -7.359375 C 3.296875 -7.421875 3.25 -7.453125 3.1875 -7.453125 C 3.09375 -7.453125 2.203125 -6.78125 1.609375 -5.515625 C 1.109375 -4.421875 0.984375 -3.3125 0.984375 -2.484375 C 0.984375 -1.703125 1.09375 -0.5 1.640625 0.609375 C 2.234375 1.84375 3.09375 2.484375 3.1875 2.484375 C 3.25 2.484375 3.296875 2.453125 3.296875 2.390625 Z M 3.296875 2.390625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph4-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.875 -2.484375 C 2.875 -3.265625 2.765625 -4.46875 2.21875 -5.578125 C 1.625 -6.8125 0.765625 -7.453125 0.671875 -7.453125 C 0.609375 -7.453125 0.5625 -7.40625 0.5625 -7.359375 C 0.5625 -7.328125 0.5625 -7.296875 0.75 -7.125 C 1.734375 -6.140625 2.296875 -4.5625 2.296875 -2.484375 C 2.296875 -0.78125 1.921875 0.96875 0.703125 2.21875 C 0.5625 2.328125 0.5625 2.359375 0.5625 2.390625 C 0.5625 2.4375 0.609375 2.484375 0.671875 2.484375 C 0.765625 2.484375 1.65625 1.8125 2.25 0.546875 C 2.75 -0.546875 2.875 -1.65625 2.875 -2.484375 Z M 2.875 -2.484375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph5-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph5-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.1875 5.3125 L 0.65625 9.671875 C 0.578125 9.765625 0.5625 9.78125 0.5625 9.828125 C 0.5625 9.9375 0.65625 9.9375 0.828125 9.9375 L 9.078125 9.9375 L 9.921875 7.46875 L 9.671875 7.46875 C 9.4375 8.203125 8.765625 8.8125 7.921875 9.109375 C 7.765625 9.15625 7.078125 9.390625 5.609375 9.390625 L 1.390625 9.390625 L 4.84375 5.125 C 4.90625 5.03125 4.921875 5.015625 4.921875 4.96875 C 4.921875 4.921875 4.921875 4.921875 4.859375 4.828125 L 1.625 0.390625 L 5.5625 0.390625 C 6.703125 0.390625 8.984375 0.46875 9.671875 2.328125 L 9.921875 2.328125 L 9.078125 0 L 0.828125 0 C 0.5625 0 0.5625 0.015625 0.5625 0.3125 Z M 4.1875 5.3125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph6-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph6-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.578125 -7.09375 C 1.578125 -7.28125 1.578125 -7.453125 1.375 -7.453125 C 1.1875 -7.453125 1.1875 -7.28125 1.1875 -7.09375 L 1.1875 2.125 C 1.1875 2.3125 1.1875 2.484375 1.375 2.484375 C 1.578125 2.484375 1.578125 2.3125 1.578125 2.125 Z M 1.578125 -7.09375 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "<clipPath id=\"clip1\">\n",
       "  <path d=\"M 0 0.0390625 L 38 0.0390625 L 38 15 L 0 15 Z M 0 0.0390625 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip2\">\n",
       "  <path d=\"M 0 297 L 38 297 L 38 311.976562 L 0 311.976562 Z M 0 297 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip3\">\n",
       "  <path d=\"M 212 125 L 334.773438 125 L 334.773438 144 L 212 144 Z M 212 125 \"/>\n",
       "</clipPath>\n",
       "</defs>\n",
       "<g id=\"surface1\">\n",
       "<g clip-path=\"url(#clip1)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -18.774417 -7.23783 L 18.774669 -7.23783 L 18.774669 7.237842 L -18.774417 7.237842 Z M -18.774417 -7.23783 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"3.513568\" y=\"7.835215\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"10.632535\" y=\"9.630928\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph2-1\" x=\"13.637034\" y=\"9.630928\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"19.851657\" y=\"9.630928\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-3\" x=\"25.827028\" y=\"9.630928\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-1\" x=\"29.904253\" y=\"9.630928\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-1\" x=\"17.557856\" y=\"49.435057\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-1\" x=\"17.557856\" y=\"53.412775\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-1\" x=\"17.557856\" y=\"57.390493\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -13.737869 -91.669462 L 13.738121 -91.669462 L 13.738121 -78.414772 L -13.737869 -78.414772 Z M -13.737869 -91.669462 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"8.539367\" y=\"93.326704\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"15.658334\" y=\"94.818972\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph2-1\" x=\"18.662833\" y=\"94.818972\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-1\" x=\"24.877456\" y=\"94.818972\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -13.737869 -134.188567 L 13.738121 -134.188567 L 13.738121 -120.933877 L -13.737869 -120.933877 Z M -13.737869 -134.188567 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"8.539367\" y=\"135.769003\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"15.658334\" y=\"137.260273\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph2-1\" x=\"18.662833\" y=\"137.260273\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-2\" x=\"24.878454\" y=\"137.260273\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -13.683081 -176.707672 L 13.683334 -176.707672 L 13.683334 -163.452982 L -13.683081 -163.452982 Z M -13.683081 -176.707672 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"8.594266\" y=\"178.211303\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"15.714232\" y=\"179.702573\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-3\" x=\"18.717733\" y=\"179.702573\"/>\n",
       "  <use xlink:href=\"#glyph3-2\" x=\"24.822579\" y=\"179.702573\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -13.683081 -219.23069 L 13.683334 -219.23069 L 13.683334 -205.972087 L -13.683081 -205.972087 Z M -13.683081 -219.23069 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"8.594266\" y=\"220.652605\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"15.714232\" y=\"222.144873\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-3\" x=\"18.717733\" y=\"222.144873\"/>\n",
       "  <use xlink:href=\"#glyph3-1\" x=\"24.822579\" y=\"222.144873\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-1\" x=\"17.557856\" y=\"261.64456\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-1\" x=\"17.557856\" y=\"265.622278\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-1\" x=\"17.557856\" y=\"269.599995\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -18.719629 -304.87939 L 18.719881 -304.87939 L 18.719881 -290.403719 L -18.719629 -290.403719 Z M -18.719629 -304.87939 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"3.568467\" y=\"304.929317\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"10.688432\" y=\"306.72503\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-3\" x=\"13.691934\" y=\"306.72503\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"19.796758\" y=\"306.72503\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-3\" x=\"25.772128\" y=\"306.72503\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-1\" x=\"29.848356\" y=\"306.72503\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 141.733737 -127.559265 C 141.733737 -119.732463 135.390113 -113.388839 127.559397 -113.388839 C 119.732595 -113.388839 113.388971 -119.732463 113.388971 -127.559265 C 113.388971 -135.389981 119.732595 -141.733605 127.559397 -141.733605 C 135.390113 -141.733605 141.733737 -135.389981 141.733737 -127.559265 Z M 141.733737 -127.559265 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph5-1\" x=\"141.016837\" y=\"129.815902\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 194.024605 -136.387898 L 316.216646 -136.387898 L 316.216646 -118.734545 L 194.024605 -118.734545 Z M 194.024605 -136.387898 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"215.922705\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-2\" x=\"220.925546\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"224.793465\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"231.912432\" y=\"138.241477\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph6-1\" x=\"238.175965\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"243.70085\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"250.819818\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph2-1\" x=\"253.824317\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"260.039938\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-3\" x=\"266.015309\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-1\" x=\"270.091536\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"274.55237\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"278.975636\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"283.388959\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"287.812225\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"292.235492\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"296.648814\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"303.770879\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-3\" x=\"306.77438\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"312.879204\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-3\" x=\"318.854574\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph3-1\" x=\"322.930802\" y=\"138.544921\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph4-3\" x=\"327.392634\" y=\"136.749209\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 7.433632 -7.437413 L 117.075395 -117.075263 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.193033 1.594017 C -1.093416 0.996293 0.00240382 0.0996999 0.301265 0.0000771957 C 0.00240241 -0.0995413 -1.09343 -0.996119 -1.193055 -1.593842 \" transform=\"matrix(0.705808,0.705798,0.705798,-0.705808,135.799029,124.322579)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"77.511098\" y=\"66.251271\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 13.937705 -89.685368 L 113.49072 -122.87101 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196238 1.593755 C -1.095996 0.996002 -0.000736629 0.0987501 0.299996 0.000979994 C -0.000737255 -0.0992634 -1.096002 -0.996508 -1.193773 -1.594261 \" transform=\"matrix(0.946906,0.315632,0.315632,-0.946906,132.223435,130.109365)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"79.025326\" y=\"110.103989\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 13.937705 -127.559265 L 112.73152 -127.559265 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.195731 1.594139 C -1.093982 0.995389 0.00176991 0.0992199 0.299188 0.00138484 C 0.00176991 -0.100364 -1.093982 -0.996532 -1.195731 -1.595283 \" transform=\"matrix(0.998173,0,0,-0.998173,131.463077,134.790445)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"78.657001\" y=\"131.27523\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 13.882917 -165.45273 L 113.49072 -132.251433 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194128 1.593195 C -1.096357 0.995442 -0.00109262 0.0981973 0.299641 -0.00204609 C -0.00109199 -0.0998162 -1.096351 -0.997068 -1.196593 -1.594821 \" transform=\"matrix(0.946906,-0.315632,-0.315632,-0.946906,132.223435,139.471545)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"78.997377\" y=\"152.455455\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 10.239541 -205.772503 L 115.220443 -135.785235 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.195764 1.594112 C -1.095894 0.996039 0.000408847 0.100575 0.29999 -0.000365829 C -0.00175868 -0.100231 -1.098032 -0.996817 -1.195711 -1.594893 \" transform=\"matrix(0.8305,-0.553646,-0.553646,-0.8305,133.949874,143.001722)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"78.014177\" y=\"174.288485\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 5.566939 -290.204136 L 118.664236 -139.424698 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196158 1.595284 C -1.094392 0.996517 -0.000930974 0.0995632 0.298065 0.000949538 C 0.00142191 -0.0992439 -1.096692 -0.99625 -1.196081 -1.59424 \" transform=\"matrix(0.598904,-0.798498,-0.798498,-0.598904,137.384746,146.633104)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"77.347398\" y=\"218.18612\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 141.93332 -127.559265 L 193.367153 -127.559265 \" transform=\"matrix(0.998173,0,0,-0.998173,18.939327,7.462897)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194904 1.594139 C -1.097069 0.995389 -0.00131682 0.0992199 0.300015 0.00138484 C -0.00131682 -0.100364 -1.097069 -0.996532 -1.194904 -1.595283 \" transform=\"matrix(0.998173,0,0,-0.998173,211.954439,134.790445)\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%tikz\n",
    "\n",
    "\\begin{tikzpicture}[node distance=1.5cm, align=center]\n",
    "    % Definición de nodos\n",
    "    \\node (w0) [rectangle, draw] {$w_{t - C/2}$};\n",
    "    \\node (dots1) [below of=w0] {$\\vdots$};\n",
    "    \\node (w1) [rectangle, draw, below of=dots1] {$w_{t-2}$};\n",
    "    \\node (w2) [rectangle, draw, below of=w1] {$w_{t-1}$};\n",
    "    \\node (w3) [rectangle, draw, below of=w2] {$w_{t+1}$};\n",
    "    \\node (w4) [rectangle, draw, below of=w3] {$w_{t+2}$};\n",
    "    \\node (dots2) [below of=w4] {$\\vdots$};\n",
    "    \\node (w5) [rectangle, draw, below of=dots2] {$w_{t+C/2}$};\n",
    "    \n",
    "    \\node (cbow) [circle, draw, right of=w2, xshift=3cm, minimum size=1cm] {$\\sum$};\n",
    "    \\node (wt) [rectangle, draw, right of=cbow, xshift=3cm] {$p(w_t\\mid w_{t-C/2},\\dots,w_{t+C/2})$};\n",
    " \n",
    "    % Flechas\n",
    "    \\draw[->] (w0) -- (cbow) node[midway, above] {$A$};            \n",
    "    \\draw[->] (w1) -- (cbow) node[midway, above] {$A$};   \n",
    "    \\draw[->] (w2) -- (cbow) node[midway, above] {$A$};   \n",
    "    \\draw[->] (w3) -- (cbow) node[midway, above] {$A$};   \n",
    "    \\draw[->] (w4) -- (cbow) node[midway, above] {$A$};   \n",
    "    \\draw[->] (w5) -- (cbow) node[midway, above] {$A$};   \n",
    "    \\draw[->] (cbow) -- (wt);\n",
    "\\end{tikzpicture}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56ca37-7e19-4fa6-8a98-202e93e3d67a",
   "metadata": {},
   "source": [
    "## Torch Dataset for CBOW training\n",
    "\n",
    "##### Task: \n",
    "\n",
    "Create a torch dataset that, on iteration, returns pairs of samples ready to train the neural probabilistic language model CBOW. The structure of your torch dataset must be something like:\n",
    "\n",
    "```python\n",
    "class CBOWDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, context_size, tokenizer):\n",
    "        ...\n",
    "        \n",
    "    def _build_dataset(self, text):\n",
    "        \"\"\"Method for building training pairs from text\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.tokenizer.vocab_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a4ce3c-0fdd-4b82-a8f2-b6c24c39647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "class CBOWDataset(torch.utils.data.Dataset):\n",
       "    def __init__(self, text, context_size, tokenizer):\n",
       "\n",
       "        self.tokenizer = tokenizer\n",
       "        self.context_size = context_size\n",
       "\n",
       "        self._build_dataset(text)\n",
       "        \n",
       "    def _build_dataset(self, text):\n",
       "\n",
       "        print(\"Tokenizing input text. Please wait...\")\n",
       "        tokenized_text = ...\n",
       "\n",
       "        print(\"Building pairs of training inputs and labels...\")\n",
       "        X = []\n",
       "        T = []\n",
       "        for i in range(self.context_size, len(tokenized_text) - self.context_size):\n",
       "            context = (\n",
       "                [tokenized_text[i - j - 1] for j in range(self.context_size)]\n",
       "                + [tokenized_text[i + j + 1] for j in range(self.context_size)]\n",
       "            )\n",
       "            target = tokenized_text[i]\n",
       "            \n",
       "            X.append(context)\n",
       "            T.append(target)\n",
       "\n",
       "        self.X = torch.tensor(...)\n",
       "        self.T = torch.tensor(...)\n",
       "\n",
       "    def __len__(self):\n",
       "        return ...\n",
       "\n",
       "    @property\n",
       "    def vocab_size(self):\n",
       "        return self.tokenizer.vocab_size\n",
       "    \n",
       "    def __getitem__(self, idx):\n",
       "        return ...\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if assesment_draw_and_fill:\n",
    "    code = \"\"\"\n",
    "```python\n",
    "class CBOWDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, context_size, tokenizer):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self._build_dataset(text)\n",
    "        \n",
    "    def _build_dataset(self, text):\n",
    "\n",
    "        print(\"Tokenizing input text. Please wait...\")\n",
    "        tokenized_text = ...\n",
    "\n",
    "        print(\"Building pairs of training inputs and labels...\")\n",
    "        X = []\n",
    "        T = []\n",
    "        for i in range(self.context_size, len(tokenized_text) - self.context_size):\n",
    "            context = (\n",
    "                [tokenized_text[i - j - 1] for j in range(self.context_size)]\n",
    "                + [tokenized_text[i + j + 1] for j in range(self.context_size)]\n",
    "            )\n",
    "            target = tokenized_text[i]\n",
    "            \n",
    "            X.append(context)\n",
    "            T.append(target)\n",
    "\n",
    "        self.X = torch.tensor(...)\n",
    "        self.T = torch.tensor(...)\n",
    "\n",
    "    def __len__(self):\n",
    "        return ...\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.tokenizer.vocab_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return ...\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966a3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, context_size, tokenizer):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self._build_dataset(text)\n",
    "        \n",
    "    def _build_dataset(self, text):\n",
    "\n",
    "        print(\"Tokenizing input text. Please wait...\")\n",
    "        tokenized_text = self.tokenizer.encode(text)\n",
    "\n",
    "        print(\"Building pairs of training inputs and labels...\")\n",
    "        X = []\n",
    "        T = []\n",
    "        for i in range(self.context_size, len(tokenized_text) - self.context_size):\n",
    "            context = (\n",
    "                [tokenized_text[i - j - 1] for j in range(self.context_size)]\n",
    "                + [tokenized_text[i + j + 1] for j in range(self.context_size)]\n",
    "            )\n",
    "            target = tokenized_text[i]\n",
    "            \n",
    "            X.append(context)\n",
    "            T.append(target)\n",
    "\n",
    "        self.X = torch.tensor(X)\n",
    "        self.T = torch.tensor(T)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.T)\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.tokenizer.vocab_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.T[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c3e29-7a41-4f69-9b41-276167d796b3",
   "metadata": {},
   "source": [
    "##### Task\n",
    "\n",
    "Read data from source, create a tokenizer, train your tokenizer and create an instance of CBOWDataset. Finally, create a dataloader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e868749-dfca-471d-88bb-861bc9dd8494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "## read data from source to train language model on \n",
       "raw_data = \"\"\n",
       "\n",
       "## reading dataset with PDF Plumber\n",
       "...\n",
       "\n",
       "## define context size\n",
       "CONTEXT_SIZE = 2 # 2 words to the left, 2 to the right\n",
       "\n",
       "## define tokenizer and train it\n",
       "tokenizer = ...\n",
       "...\n",
       "\n",
       "## Create dataset instance\n",
       "text_dataset = CBOWDataset(..., ..., ...)\n",
       "\n",
       "\n",
       "## Create dataloader\n",
       "cbow_loader = torch.utils.data.DataLoader(\n",
       "                                                dataset = ...,\n",
       "                                                batch_size = ..., \n",
       "                                                shuffle=True,\n",
       "                                                num_workers=0,\n",
       "                                            )\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if assesment_draw_and_fill:\n",
    "    code = \"\"\"\n",
    "```python\n",
    "## read data from source to train language model on \n",
    "raw_data = \"\"\n",
    "\n",
    "## reading dataset with PDF Plumber\n",
    "...\n",
    "\n",
    "## define context size\n",
    "CONTEXT_SIZE = 2 # 2 words to the left, 2 to the right\n",
    "\n",
    "## define tokenizer and train it\n",
    "tokenizer = ...\n",
    "...\n",
    "\n",
    "## Create dataset instance\n",
    "text_dataset = CBOWDataset(..., ..., ...)\n",
    "\n",
    "\n",
    "## Create dataloader\n",
    "cbow_loader = torch.utils.data.DataLoader(\n",
    "                                                dataset = ...,\n",
    "                                                batch_size = ..., \n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0,\n",
    "                                            )\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6910de-10a9-420c-be6e-8ebf7790eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data...\n",
      "Pre tokenizing data...\n",
      "Building vocabulary...\n",
      "Building ids to word mappings...\n",
      "Tokenizing input text. Please wait...\n",
      "Building pairs of training inputs and labels...\n"
     ]
    }
   ],
   "source": [
    "## read data from source to train language model on \n",
    "raw_data = \"\"\n",
    "\n",
    "## reading dataset with PDF Plumber\n",
    "with pdfplumber.open('data/texto_pdf.pdf') as pdf:\n",
    "    for page in pdf.pages:\n",
    "        raw_data += page.extract_text()\n",
    "\n",
    "## define context size\n",
    "CONTEXT_SIZE = 2 # 2 words to the left, 2 to the right\n",
    "\n",
    "## define tokenizer and train it\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.train_tokenizer(raw_data)\n",
    "\n",
    "## create dataset instance\n",
    "text_dataset = CBOWDataset(raw_data, CONTEXT_SIZE, tokenizer)\n",
    "\n",
    "## create dataloader\n",
    "cbow_loader = torch.utils.data.DataLoader(\n",
    "                                                dataset = text_dataset,\n",
    "                                                batch_size = 100, \n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5901a-7aaa-4dae-a3ac-f5d7a01491c1",
   "metadata": {},
   "source": [
    "## Torch nn CBOW Model \n",
    "\n",
    "##### Task \n",
    "\n",
    "Implement a torch nn module that implements the CBOW probabilistic model. Use the following structure:\n",
    "\n",
    "```python\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, d_embedding, vocab_size):\n",
    "        ...\n",
    "        \n",
    "    def forward(self, context_ids):\n",
    "        ...\n",
    "        \n",
    "    def compute_loss(self,y,t):\n",
    "        ...\n",
    "```\n",
    "\n",
    "Then create a model instance. Choose whatever embedding dimension you want. Example:\n",
    "\n",
    "```python\n",
    "## Create model\n",
    "model = CBOW(d_embedding = 400, vocab_size = text_dataset.vocab_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0b0f56-226b-447f-89bd-1c34c4ac85dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "class CBOW(nn.Module):\n",
       "    def __init__(self, d_embedding, vocab_size):\n",
       "        super().__init__()\n",
       "        \n",
       "        self.embedding_matrix = ...\n",
       "        self.A = ... \n",
       "        self.loss = ...\n",
       "        \n",
       "    def forward(self, context_ids):\n",
       "        ...\n",
       "        return torch.matmul(..., ...)\n",
       "        \n",
       "    def compute_loss(self,y,t):\n",
       "        return ...\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if assesment_draw_and_fill:\n",
    "    code = \"\"\"\n",
    "```python\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, d_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_matrix = ...\n",
    "        self.A = ... \n",
    "        self.loss = ...\n",
    "        \n",
    "    def forward(self, context_ids):\n",
    "        ...\n",
    "        return torch.matmul(..., ...)\n",
    "        \n",
    "    def compute_loss(self,y,t):\n",
    "        return ...\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e1ee03-9be3-43ec-905b-ce6046c761f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, d_embedding, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_matrix = nn.Parameter(torch.randn(vocab_size, d_embedding))\n",
    "        self.A = nn.Parameter(torch.randn(d_embedding, vocab_size))\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, context_ids):\n",
    "        e = self.embedding_matrix[context_ids,:]\n",
    "        return torch.matmul(torch.sum(e,-2), self.A)\n",
    "        \n",
    "    def compute_loss(self,y,t):\n",
    "        return self.loss(y,t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13648d4-2069-429e-a0ad-9a9de50b9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create model instance\n",
    "model = CBOW(d_embedding = 400, vocab_size = text_dataset.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebd7e3-a627-4bbd-ae1f-209c431f5af6",
   "metadata": {},
   "source": [
    "## Learn Language Model\n",
    "\n",
    "Note that embeddings are vector living in a high dimensional euclidean space. We could find similar vectors either by using the euclidean distance or by measuring how aligned the vectors are. For many reasons (see the theoretical description) we use alignment.\n",
    "\n",
    "Two vectors are aligned when their angle is $0$. Thus, we can use the dot product to compute how aligned two vectors are since:\n",
    "\n",
    "$$\n",
    "a\\cdot b = \\mid a\\mid\\mid b\\mid \\cos \\theta\n",
    "$$\n",
    "\n",
    "When $\\cos \\theta$ is $1$ the vectors are totally aligned. \n",
    "\n",
    "##### Task: Implement a function that receives a list of words, the embedding matrix, the tokenizer and a parameter K, and displays the K most similar words. The structure of function should be:\n",
    "\n",
    "```python\n",
    "def find_closest_words(words_to_inspect,embedding_matrix,tokenizer, K):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc034e64-7fe7-4a6c-b49b-7315f33c4468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "def find_closest_words(words_to_inspect, embedding_matrix, tokenizer, K):\n",
       "    norm_embedding_matrix = (embedding_matrix**2).sum(1).sqrt()\n",
       "    \n",
       "    ## for each token find closest vectors using dot product (NOTE this could be easily done in a single matrix product, however did\n",
       "    #  this way since it is more didactic.\n",
       "    for word, token in zip(...,...):\n",
       "        word_embedding = ...\n",
       "    \n",
       "        norm = (word_embedding**2).sum().sqrt()\n",
       "    \n",
       "        # distances via angle of vectors\n",
       "        vectors_angle = torch.matmul(...,...) / (... * ...)\n",
       "    \n",
       "        # sort distances and get ids\n",
       "        sorted_distances, sorted_ids = torch.sort(..., descending = True) \n",
       "    \n",
       "        # to decode adequately \n",
       "        sorted_ids = [[s] for s in sorted_ids.squeeze().numpy().tolist()]\n",
       "    \n",
       "        # decode the list of sorted_ids into their corresponding words\n",
       "        closest_word = ...\n",
       "    \n",
       "    \n",
       "        print(\"=========================================\")\n",
       "        print(f\"For word: {word} \")\n",
       "        print(f\"Closest words: {closest_word[0:K]}\")\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if assesment_draw_and_fill:\n",
    "    code = \"\"\"\n",
    "```python\n",
    "def find_closest_words(words_to_inspect, embedding_matrix, tokenizer, K):\n",
    "    norm_embedding_matrix = (embedding_matrix**2).sum(1).sqrt()\n",
    "    \n",
    "    ## for each token find closest vectors using dot product (NOTE this could be easily done in a single matrix product, however did\n",
    "    #  this way since it is more didactic.\n",
    "    for word, token in zip(...,...):\n",
    "        word_embedding = ...\n",
    "    \n",
    "        norm = (word_embedding**2).sum().sqrt()\n",
    "    \n",
    "        # distances via angle of vectors\n",
    "        vectors_angle = torch.matmul(...,...) / (... * ...)\n",
    "    \n",
    "        # sort distances and get ids\n",
    "        sorted_distances, sorted_ids = torch.sort(..., descending = True) \n",
    "    \n",
    "        # to decode adequately \n",
    "        sorted_ids = [[s] for s in sorted_ids.squeeze().numpy().tolist()]\n",
    "    \n",
    "        # decode the list of sorted_ids into their corresponding words\n",
    "        closest_word = ...\n",
    "    \n",
    "    \n",
    "        print(\"=========================================\")\n",
    "        print(f\"For word: {word} \")\n",
    "        print(f\"Closest words: {closest_word[0:K]}\")\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(code))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502f6b1d-d734-41ea-87c3-a94546d29f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_words(words_to_inspect, embedding_matrix, tokenizer, K):\n",
    "    norm_embedding_matrix = (embedding_matrix**2).sum(1).sqrt()\n",
    "    \n",
    "    ## for each token find closest vectors using dot product (NOTE this could be easily done in a single matrix product, however did\n",
    "    #  this way since it is more didactic.\n",
    "    for word, token in zip(words_to_inspect,tokenizer.batch_encode(words_to_inspect)):\n",
    "        word_embedding = embedding_matrix[token,:]\n",
    "    \n",
    "        norm = (word_embedding**2).sum().sqrt()\n",
    "    \n",
    "        # distances via angle of vectors\n",
    "        vectors_angle = torch.matmul(word_embedding,embedding_matrix.t()) / (norm * norm_embedding_matrix)\n",
    "    \n",
    "        # sort distances and get ids\n",
    "        sorted_distances, sorted_ids = torch.sort(vectors_angle, descending = True) \n",
    "    \n",
    "        # to decode adequately \n",
    "        sorted_ids = [[s] for s in sorted_ids.squeeze().numpy().tolist()]\n",
    "    \n",
    "        # decode the list of sorted_ids into their corresponding words\n",
    "        closest_word = tokenizer.batch_decode(sorted_ids)\n",
    "    \n",
    "    \n",
    "        print(\"=========================================\")\n",
    "        print(f\"For word: {word} \")\n",
    "        print(f\"Closest words: {closest_word[0:K]}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574164b8-65d0-4737-937a-cbf99fb04525",
   "metadata": {},
   "source": [
    "#####  Task Inspect embeddings before training\n",
    "\n",
    "Call the function and on a vector of words, for example:\n",
    "\n",
    "```python\n",
    "words_to_inspect = ['red', 'neuronal','datos', 'maquina', 'tesla', 'imagen', 'coches','foto', 'machine', 'learning','colores']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211bc55a-3308-4e0d-98a1-3a663cb312bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "For word: red \n",
      "Closest words: ['red', 'rompecabezas', 'usan', 'linea', 'procesar', 'adelante', 'vertical', 'respuesta', 'esos', 'final']\n",
      "=========================================\n",
      "For word: neuronal \n",
      "Closest words: ['neuronal', 'podian', 'precisa', 'capas', 'ahorrar', 'automatico', 'correcta', 'detectan', 'habeis', 'numero']\n",
      "=========================================\n",
      "For word: datos \n",
      "Closest words: ['datos', 'o', ':', 'estructura', 'hacer', 'finalmente', 'audio', 'estudiar', 'diferente', 'conducen']\n",
      "=========================================\n",
      "For word: maquina \n",
      "Closest words: ['maquina', 'pueden', 'puntos', 'predecir', 'capaz', 'otras', 'practico', 'seguridad', 'identificar', 'rompecabezas']\n",
      "=========================================\n",
      "For word: tesla \n",
      "Closest words: ['tesla', 'juntas', 'eso', 'reconocemos', 'esas', 'peatones', 'semaforos', 'cuantas', 'lo', 'del']\n",
      "=========================================\n",
      "For word: imagen \n",
      "Closest words: ['imagen', 'encargarian', 'puntos', 'cruzada', 'con', '.', 'su', 'aplicaciones', 'todo', '\"']\n",
      "=========================================\n",
      "For word: coches \n",
      "Closest words: ['coches', 'dato', 'cosas', 'antes', 'procesamiento', 'tipico', 'principio', 'problemas', 'complejo', 'va']\n",
      "=========================================\n",
      "For word: foto \n",
      "Closest words: ['foto', 'horizontal', 'coche', 'inspiracion', 'inspiradas', 'del', '1', 'seria', 'meterlos', 'hacen']\n",
      "=========================================\n",
      "For word: machine \n",
      "Closest words: ['machine', 'cuantas', 'suficientemente', 'recibe', 'tiempo', 'resolver', 'estan', 'objetivo', 'numero', 'rama']\n",
      "=========================================\n",
      "For word: learning \n",
      "Closest words: ['learning', 'partes', 'esas', 'precisa', 'correcta', 'deep', 'trabajado', 'aprende', 'seguridad', 'persona']\n",
      "=========================================\n",
      "For word: colores \n",
      "Closest words: ['colores', 'cuantas', 'luego', 'ejemplo', 'no', 'acelerar', 'esquinas', 'tambien', 'detectar', 'del']\n"
     ]
    }
   ],
   "source": [
    "words_to_inspect = ['red', 'neuronal','datos', 'maquina', 'tesla', 'imagen', 'coches','foto', 'machine', 'learning','colores']\n",
    "embedding_matrix = model.embedding_matrix\n",
    "\n",
    "find_closest_words(words_to_inspect, embedding_matrix, tokenizer, K = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9194407",
   "metadata": {},
   "source": [
    "##### Task: Train Model\n",
    "\n",
    "Train your model in an optimization loop. As learning algorithm you can choose SGD with momentum or Adam. You are also free of experimenting with learning rate and so on so that your loss minimize adequately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4644d57d-f2b1-4af2-8dbe-e219c8b38761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "## Optimizer\n",
       "optimizer = ...\n",
       "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.1)\n",
       "\n",
       "epochs = ...\n",
       "for e in range(epochs):\n",
       "    loss_acc = 0.0\n",
       "    for batch_idx, ... in enumerate(...):\n",
       "        \n",
       "        ## forward\n",
       "        y = ...\n",
       "        L = ...\n",
       "        \n",
       "        ## backward\n",
       "        L...\n",
       "        loss_acc += L.item()\n",
       "        \n",
       "        ## update\n",
       "        ...\n",
       "        \n",
       "        ## zero grad\n",
       "        ...\n",
       "\n",
       "        print(f\"Running batch_idx {batch_idx}/{len(cbow_loader)}\", end = \"\r",
       "\")\n",
       "\n",
       "    ## update scheduler\n",
       "    scheduler.step()\n",
       " \n",
       "    print(f\"Loss epoch {e} got {loss_acc}\")   \n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if assesment_draw_and_fill:\n",
    "    code = \"\"\"\n",
    "```python\n",
    "## Optimizer\n",
    "optimizer = ...\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.1)\n",
    "\n",
    "epochs = ...\n",
    "for e in range(epochs):\n",
    "    loss_acc = 0.0\n",
    "    for batch_idx, ... in enumerate(...):\n",
    "        \n",
    "        ## forward\n",
    "        y = ...\n",
    "        L = ...\n",
    "        \n",
    "        ## backward\n",
    "        L...\n",
    "        loss_acc += L.item()\n",
    "        \n",
    "        ## update\n",
    "        ...\n",
    "        \n",
    "        ## zero grad\n",
    "        ...\n",
    "\n",
    "        print(f\"Running batch_idx {batch_idx}/{len(cbow_loader)}\", end = \"\\r\")\n",
    "\n",
    "    ## update scheduler\n",
    "    scheduler.step()\n",
    " \n",
    "    print(f\"Loss epoch {e} got {loss_acc}\")   \n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(code))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601041fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss epoch 0 got 1286.0601959228516\n",
      "Loss epoch 1 got 1194.0753707885742\n",
      "Loss epoch 2 got 1092.0502624511719\n",
      "Loss epoch 3 got 997.8328399658203\n",
      "Loss epoch 4 got 904.7905502319336\n",
      "Loss epoch 5 got 820.1842727661133\n",
      "Loss epoch 6 got 748.4465370178223\n",
      "Loss epoch 7 got 693.8679733276367\n",
      "Loss epoch 8 got 643.9393653869629\n",
      "Loss epoch 9 got 583.1517333984375\n",
      "Loss epoch 10 got 546.1926612854004\n",
      "Loss epoch 11 got 505.1980667114258\n",
      "Loss epoch 12 got 466.46518325805664\n",
      "Loss epoch 13 got 428.6425018310547\n",
      "Loss epoch 14 got 390.2106113433838\n",
      "Loss epoch 15 got 363.07573318481445\n",
      "Loss epoch 16 got 331.552490234375\n",
      "Loss epoch 17 got 305.2742214202881\n",
      "Loss epoch 18 got 279.4083023071289\n",
      "Loss epoch 19 got 260.23000717163086\n",
      "Loss epoch 20 got 244.67745399475098\n",
      "Loss epoch 21 got 216.20709037780762\n",
      "Loss epoch 22 got 197.71891975402832\n",
      "Loss epoch 23 got 183.1949348449707\n",
      "Loss epoch 24 got 165.3056697845459\n",
      "Loss epoch 25 got 151.38202095031738\n",
      "Loss epoch 26 got 137.43899059295654\n",
      "Loss epoch 27 got 120.45336818695068\n",
      "Loss epoch 28 got 107.14348030090332\n",
      "Loss epoch 29 got 97.6624493598938\n",
      "Loss epoch 30 got 85.29008865356445\n",
      "Loss epoch 31 got 79.13482713699341\n",
      "Loss epoch 32 got 69.0150318145752\n",
      "Loss epoch 33 got 60.12989830970764\n",
      "Loss epoch 34 got 52.48594260215759\n",
      "Loss epoch 35 got 44.72621774673462\n",
      "Loss epoch 36 got 39.17330288887024\n",
      "Loss epoch 37 got 33.54196393489838\n",
      "Loss epoch 38 got 31.124275982379913\n",
      "Loss epoch 39 got 25.594951033592224\n",
      "Loss epoch 40 got 22.807432889938354\n",
      "Loss epoch 41 got 18.877575159072876\n",
      "Loss epoch 42 got 16.64858067035675\n",
      "Loss epoch 43 got 13.83555006980896\n",
      "Loss epoch 44 got 10.506204098463058\n",
      "Loss epoch 45 got 9.244311451911926\n",
      "Loss epoch 46 got 7.165948241949081\n",
      "Loss epoch 47 got 5.923573598265648\n",
      "Loss epoch 48 got 4.895949445664883\n",
      "Loss epoch 49 got 4.298412948846817\n",
      "Loss epoch 50 got 3.437391072511673\n",
      "Loss epoch 51 got 3.2539922446012497\n",
      "Loss epoch 52 got 3.5302663445472717\n",
      "Loss epoch 53 got 3.4970150366425514\n",
      "Loss epoch 54 got 3.031124360859394\n",
      "Loss epoch 55 got 3.297677181661129\n",
      "Loss epoch 56 got 3.227521315217018\n",
      "Loss epoch 57 got 2.838758695870638\n",
      "Loss epoch 58 got 2.9811789132654667\n",
      "Loss epoch 59 got 2.841488279402256\n",
      "Loss epoch 60 got 2.661632314324379\n",
      "Loss epoch 61 got 2.8987126499414444\n",
      "Loss epoch 62 got 3.107653632760048\n",
      "Loss epoch 63 got 2.8110776841640472\n",
      "Loss epoch 64 got 2.391465660184622\n",
      "Loss epoch 65 got 2.3403572030365467\n",
      "Loss epoch 66 got 2.3469955176115036\n",
      "Loss epoch 67 got 2.3108895756304264\n",
      "Loss epoch 68 got 2.5253026857972145\n",
      "Loss epoch 69 got 2.155318722128868\n",
      "Loss epoch 70 got 2.2452999018132687\n",
      "Loss epoch 71 got 2.0430163480341434\n",
      "Loss epoch 72 got 2.017062194645405\n",
      "Loss epoch 73 got 2.07770586758852\n",
      "Loss epoch 74 got 2.350543387234211\n",
      "Loss epoch 75 got 2.425822749733925\n",
      "Loss epoch 76 got 1.8249406442046165\n",
      "Loss epoch 77 got 1.7885499373078346\n",
      "Loss epoch 78 got 1.7822822779417038\n",
      "Loss epoch 79 got 1.73150534927845\n",
      "Loss epoch 80 got 1.6680355854332447\n",
      "Loss epoch 81 got 1.809445582330227\n",
      "Loss epoch 82 got 1.5995644181966782\n",
      "Loss epoch 83 got 1.5565918646752834\n",
      "Loss epoch 84 got 1.5172564387321472\n",
      "Loss epoch 85 got 1.6058852821588516\n",
      "Loss epoch 86 got 1.5705291703343391\n",
      "Loss epoch 87 got 1.4022130891680717\n",
      "Loss epoch 88 got 1.379066813737154\n",
      "Loss epoch 89 got 1.4043559804558754\n",
      "Loss epoch 90 got 1.3245165757834911\n",
      "Loss epoch 91 got 1.312518261373043\n",
      "Loss epoch 92 got 1.2447245121002197\n",
      "Loss epoch 93 got 1.2271581180393696\n",
      "Loss epoch 94 got 1.1815458573400974\n",
      "Loss epoch 95 got 1.1614634059369564\n",
      "Loss epoch 96 got 1.1310060694813728\n",
      "Loss epoch 97 got 1.1669545210897923\n",
      "Loss epoch 98 got 1.0775146968662739\n",
      "Loss epoch 99 got 1.0551357679069042\n",
      "Loss epoch 100 got 1.1950830891728401\n",
      "Loss epoch 101 got 1.0521069951355457\n",
      "Loss epoch 102 got 1.0526911467313766\n",
      "Loss epoch 103 got 1.0380702912807465\n",
      "Loss epoch 104 got 1.0762611590325832\n",
      "Loss epoch 105 got 1.0266391783952713\n",
      "Loss epoch 106 got 1.291584175080061\n",
      "Loss epoch 107 got 1.0164674520492554\n",
      "Loss epoch 108 got 1.007650125771761\n",
      "Loss epoch 109 got 1.0208426155149937\n",
      "Loss epoch 110 got 1.0001186095178127\n",
      "Loss epoch 111 got 1.0936026759445667\n",
      "Loss epoch 112 got 1.003453865647316\n",
      "Loss epoch 113 got 1.0011093318462372\n",
      "Loss epoch 114 got 1.0937452018260956\n",
      "Loss epoch 115 got 0.9952278360724449\n",
      "Loss epoch 116 got 0.9908988922834396\n",
      "Loss epoch 117 got 1.00348798930645\n",
      "Loss epoch 118 got 0.9923999160528183\n",
      "Loss epoch 119 got 1.009902998805046\n",
      "Loss epoch 120 got 0.9981501176953316\n",
      "Loss epoch 121 got 1.0018318481743336\n",
      "Loss epoch 122 got 1.1252001971006393\n",
      "Loss epoch 123 got 0.9857375286519527\n",
      "Loss epoch 124 got 0.97486237809062\n",
      "Loss epoch 125 got 0.9917104914784431\n",
      "Loss epoch 126 got 0.9701815098524094\n",
      "Loss epoch 127 got 1.0458625331521034\n",
      "Loss epoch 128 got 0.9660203568637371\n",
      "Loss epoch 129 got 1.0011352710425854\n",
      "Loss epoch 130 got 0.9556573145091534\n",
      "Loss epoch 131 got 0.9651046767830849\n",
      "Loss epoch 132 got 0.9582116678357124\n",
      "Loss epoch 133 got 0.9847598262131214\n",
      "Loss epoch 134 got 0.9667466580867767\n",
      "Loss epoch 135 got 0.9579888917505741\n",
      "Loss epoch 136 got 0.9431888237595558\n",
      "Loss epoch 137 got 0.9414406791329384\n",
      "Loss epoch 138 got 0.9434477090835571\n",
      "Loss epoch 139 got 0.9614477045834064\n",
      "Loss epoch 140 got 0.9540158808231354\n",
      "Loss epoch 141 got 0.9503838010132313\n",
      "Loss epoch 142 got 0.9462152794003487\n",
      "Loss epoch 143 got 1.0151523239910603\n",
      "Loss epoch 144 got 0.9258137904107571\n",
      "Loss epoch 145 got 1.0105876363813877\n",
      "Loss epoch 146 got 0.934327132999897\n",
      "Loss epoch 147 got 0.9312839992344379\n",
      "Loss epoch 148 got 0.9234766624867916\n",
      "Loss epoch 149 got 0.9217891059815884\n",
      "Loss epoch 150 got 0.9241555668413639\n",
      "Loss epoch 151 got 1.2108940035104752\n",
      "Loss epoch 152 got 0.9481991864740849\n",
      "Loss epoch 153 got 0.9555133059620857\n",
      "Loss epoch 154 got 0.928309716284275\n",
      "Loss epoch 155 got 0.921560350805521\n",
      "Loss epoch 156 got 0.9139125011861324\n",
      "Loss epoch 157 got 0.9104698672890663\n",
      "Loss epoch 158 got 0.9067456293851137\n",
      "Loss epoch 159 got 0.9165453054010868\n",
      "Loss epoch 160 got 0.9964894726872444\n",
      "Loss epoch 161 got 0.9198469966650009\n",
      "Loss epoch 162 got 0.9515823237597942\n",
      "Loss epoch 163 got 0.9141771011054516\n",
      "Loss epoch 164 got 1.054632507264614\n",
      "Loss epoch 165 got 0.9106716923415661\n",
      "Loss epoch 166 got 1.1979908309876919\n",
      "Loss epoch 167 got 1.0379287004470825\n",
      "Loss epoch 168 got 1.1533171087503433\n",
      "Loss epoch 169 got 0.9147540777921677\n",
      "Loss epoch 170 got 0.9289418943226337\n",
      "Loss epoch 171 got 0.9295679181814194\n",
      "Loss epoch 172 got 0.9105539545416832\n",
      "Loss epoch 173 got 0.9106809571385384\n",
      "Loss epoch 174 got 0.911373283714056\n",
      "Loss epoch 175 got 0.9204630739986897\n",
      "Loss epoch 176 got 0.9204815961420536\n",
      "Loss epoch 177 got 0.9131611920893192\n",
      "Loss epoch 178 got 0.9086197577416897\n",
      "Loss epoch 179 got 0.916749894618988\n",
      "Loss epoch 180 got 0.9067103751003742\n",
      "Loss epoch 181 got 1.1579476036131382\n",
      "Loss epoch 182 got 0.9088143743574619\n",
      "Loss epoch 183 got 0.9454828165471554\n",
      "Loss epoch 184 got 0.9209064096212387\n",
      "Loss epoch 185 got 0.9133064262568951\n",
      "Loss epoch 186 got 1.161654930561781\n",
      "Loss epoch 187 got 0.905628077685833\n",
      "Loss epoch 188 got 0.912421215325594\n",
      "Loss epoch 189 got 1.0414401441812515\n",
      "Loss epoch 190 got 0.9251995831727982\n",
      "Loss epoch 191 got 0.9123118221759796\n",
      "Loss epoch 192 got 0.9076442718505859\n",
      "Loss epoch 193 got 0.9197804890573025\n",
      "Loss epoch 194 got 0.9076971486210823\n",
      "Loss epoch 195 got 0.915516123175621\n",
      "Loss epoch 196 got 0.9167185574769974\n",
      "Loss epoch 197 got 0.919285237789154\n",
      "Loss epoch 198 got 0.9173980578780174\n",
      "Loss epoch 199 got 0.9154546111822128\n",
      "Loss epoch 200 got 1.0399754606187344\n",
      "Loss epoch 201 got 0.9232937842607498\n",
      "Loss epoch 202 got 0.9338948726654053\n",
      "Loss epoch 203 got 0.91100163012743\n",
      "Loss epoch 204 got 0.9864313304424286\n",
      "Loss epoch 205 got 0.9234257154166698\n",
      "Loss epoch 206 got 0.9734969958662987\n",
      "Loss epoch 207 got 0.9114987142384052\n",
      "Loss epoch 208 got 0.9033062420785427\n",
      "Loss epoch 209 got 0.9340439289808273\n",
      "Loss epoch 210 got 0.9104859344661236\n",
      "Loss epoch 211 got 0.9932608343660831\n",
      "Loss epoch 212 got 0.9299183264374733\n",
      "Loss epoch 213 got 0.9083170928061008\n",
      "Loss epoch 214 got 0.9071744792163372\n",
      "Loss epoch 215 got 0.924712561070919\n",
      "Loss epoch 216 got 1.1587458178400993\n",
      "Loss epoch 217 got 0.906864520162344\n",
      "Loss epoch 218 got 1.156076867133379\n",
      "Loss epoch 219 got 0.9117265418171883\n",
      "Loss epoch 220 got 0.9010523837059736\n",
      "Loss epoch 221 got 0.90959233045578\n",
      "Loss epoch 222 got 0.9155494347214699\n",
      "Loss epoch 223 got 0.9137664698064327\n",
      "Loss epoch 224 got 0.9252081029117107\n",
      "Loss epoch 225 got 0.9067056439816952\n",
      "Loss epoch 226 got 0.9334176443517208\n",
      "Loss epoch 227 got 0.9140221551060677\n",
      "Loss epoch 228 got 0.9093584679067135\n",
      "Loss epoch 229 got 0.9182295985519886\n",
      "Loss epoch 230 got 0.9298938661813736\n",
      "Loss epoch 231 got 0.9064480513334274\n",
      "Loss epoch 232 got 0.92170599848032\n",
      "Loss epoch 233 got 0.9000753909349442\n",
      "Loss epoch 234 got 0.9182912893593311\n",
      "Loss epoch 235 got 0.905994076281786\n",
      "Loss epoch 236 got 0.9092089161276817\n",
      "Loss epoch 237 got 0.9046434126794338\n",
      "Loss epoch 238 got 0.9103831984102726\n",
      "Loss epoch 239 got 1.0302528962492943\n",
      "Loss epoch 240 got 1.041309230029583\n",
      "Loss epoch 241 got 0.9140337780117989\n",
      "Loss epoch 242 got 0.9154327474534512\n",
      "Loss epoch 243 got 0.9079482182860374\n",
      "Loss epoch 244 got 0.9077485054731369\n",
      "Loss epoch 245 got 1.0505902953445911\n",
      "Loss epoch 246 got 0.9518242292106152\n",
      "Loss epoch 247 got 0.9659275785088539\n",
      "Loss epoch 248 got 0.9072352461516857\n",
      "Loss epoch 249 got 0.9092298336327076\n",
      "Loss epoch 250 got 0.9307372830808163\n",
      "Loss epoch 251 got 1.1484660096466541\n",
      "Loss epoch 252 got 1.066168550401926\n",
      "Loss epoch 253 got 0.9118248820304871\n",
      "Loss epoch 254 got 0.9881809614598751\n",
      "Loss epoch 255 got 0.9517756663262844\n",
      "Loss epoch 256 got 0.9290846399962902\n",
      "Loss epoch 257 got 0.9218115322291851\n",
      "Loss epoch 258 got 0.908714059740305\n",
      "Loss epoch 259 got 1.1472538821399212\n",
      "Loss epoch 260 got 0.942391999065876\n",
      "Loss epoch 261 got 0.9055658467113972\n",
      "Loss epoch 262 got 1.0557382069528103\n",
      "Loss epoch 263 got 0.921166006475687\n",
      "Loss epoch 264 got 0.906685471534729\n",
      "Loss epoch 265 got 0.9124682918190956\n",
      "Loss epoch 266 got 0.9214808866381645\n",
      "Loss epoch 267 got 0.9078711941838264\n",
      "Loss epoch 268 got 0.9180956482887268\n",
      "Loss epoch 269 got 0.9033741094172001\n",
      "Loss epoch 270 got 0.9138688892126083\n",
      "Loss epoch 271 got 0.9049057140946388\n",
      "Loss epoch 272 got 0.9213734194636345\n",
      "Loss epoch 273 got 0.9198436327278614\n",
      "Loss epoch 274 got 0.9640980586409569\n",
      "Loss epoch 275 got 0.9094001278281212\n",
      "Loss epoch 276 got 0.9431443214416504\n",
      "Loss epoch 277 got 0.9080225080251694\n",
      "Loss epoch 278 got 0.9073736667633057\n",
      "Loss epoch 279 got 0.9283741600811481\n",
      "Loss epoch 280 got 0.9263625182211399\n",
      "Loss epoch 281 got 0.9130882732570171\n",
      "Loss epoch 282 got 0.9199813231825829\n",
      "Loss epoch 283 got 0.9103854820132256\n",
      "Loss epoch 284 got 0.9251162447035313\n",
      "Loss epoch 285 got 0.9051909483969212\n",
      "Loss epoch 286 got 0.9028779119253159\n",
      "Loss epoch 287 got 0.89992406219244\n",
      "Loss epoch 288 got 1.0005892626941204\n",
      "Loss epoch 289 got 0.9084899686276913\n",
      "Loss epoch 290 got 0.9164370261132717\n",
      "Loss epoch 291 got 0.9044022560119629\n",
      "Loss epoch 292 got 0.9581665247678757\n",
      "Loss epoch 293 got 0.9162255227565765\n",
      "Loss epoch 294 got 0.905050452798605\n",
      "Loss epoch 295 got 0.9095467776060104\n",
      "Loss epoch 296 got 1.156842052936554\n",
      "Loss epoch 297 got 0.9239220656454563\n",
      "Loss epoch 298 got 0.9116789512336254\n",
      "Loss epoch 299 got 0.9221581853926182\n"
     ]
    }
   ],
   "source": [
    "## Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "epochs = 300\n",
    "for e in range(epochs):\n",
    "    loss_acc = 0.0\n",
    "    for batch_idx, (x,t) in enumerate(cbow_loader):\n",
    "        \n",
    "        ## forward\n",
    "        y = model(x)\n",
    "        L = model.compute_loss(y,t)\n",
    "        \n",
    "        ## backward\n",
    "        L.backward()\n",
    "        loss_acc += L.item()\n",
    "        \n",
    "        ## update\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Running batch_idx {batch_idx}/{len(cbow_loader)}\", end = \"\\r\")\n",
    "\n",
    "    ## update scheduler\n",
    "    scheduler.step()\n",
    " \n",
    "    print(f\"Loss epoch {e} got {loss_acc}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ace65-9107-44d1-b6b6-02818035d043",
   "metadata": {},
   "source": [
    "##### Task: Inspect learned embeddings\n",
    "\n",
    "Call again the function on the same list as before and inspect which are now the closest embeddings\n",
    "Let's see what the model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "643cf2d4-81df-4123-b9be-28b3336cf59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "For word: red \n",
      "Closest words: ['red', 'rompecabezas', 'linea', 'vertical', 'respuesta', 'redes', 'usan', 'simples', 'adelante', 'utiles']\n",
      "=========================================\n",
      "For word: neuronal \n",
      "Closest words: ['neuronal', 'precisa', 'podian', 'o', 'capas', 'ahorrar', 'detectan', 'habeis', 'automatico', 'numero']\n",
      "=========================================\n",
      "For word: datos \n",
      "Closest words: ['datos', 'estructura', 'hacer', 'o', 'conducen', 'audio', ':', 'finalmente', 'estudiar', 'diferente']\n",
      "=========================================\n",
      "For word: maquina \n",
      "Closest words: ['maquina', 'pueden', 'puntos', 'predecir', 'seguridad', 'practico', 'otras', 'learning', 'rompecabezas', 'capaz']\n",
      "=========================================\n",
      "For word: tesla \n",
      "Closest words: ['tesla', 'juntas', 'eso', 'reconocemos', 'es', 'alrededor', 'peatones', 'del', 'esas', 'semaforos']\n",
      "=========================================\n",
      "For word: imagen \n",
      "Closest words: ['imagen', 'puntos', 'encargarian', 'cruzada', 'aplicaciones', 'con', '.', 'todo', 'parecido', 'su']\n",
      "=========================================\n",
      "For word: coches \n",
      "Closest words: ['coches', 'dato', 'antes', 'cosas', 'y', 'procesamiento', 'tipico', 'principio', 'con', 'complejo']\n",
      "=========================================\n",
      "For word: foto \n",
      "Closest words: ['foto', 'inspiracion', 'inspiradas', 'horizontal', 'coche', 'seria', '1', 'del', 'que', 'meterlos']\n",
      "=========================================\n",
      "For word: machine \n",
      "Closest words: ['machine', 'cuantas', 'suficientemente', 'recibe', 'tiempo', 'estan', 'numero', 'resolver', '.', 'objetivo']\n",
      "=========================================\n",
      "For word: learning \n",
      "Closest words: ['learning', 'partes', 'precisa', 'esas', 'correcta', 'aprende', 'un', 'maquina', 'persona', 'seguridad']\n",
      "=========================================\n",
      "For word: colores \n",
      "Closest words: ['colores', 'cuantas', 'luego', 'no', 'acelerar', 'esquinas', 'tambien', 'del', 'ejemplo', 'capaces']\n"
     ]
    }
   ],
   "source": [
    "words_to_inspect = ['red', 'neuronal','datos', 'maquina', 'tesla', 'imagen', 'coches','foto', 'machine', 'learning','colores']\n",
    "embedding_matrix = model.embedding_matrix\n",
    "\n",
    "find_closest_words(words_to_inspect, embedding_matrix, tokenizer, K = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8ac9c-20f0-4036-a131-b20569bbd72f",
   "metadata": {},
   "source": [
    "# Optional: implement the skip gram neural probabilistic language model"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
